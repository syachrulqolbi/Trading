{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data_fetcher import YahooFinanceDataFetcher\n",
    "from mt5_fetcher import MT5DataFetcher\n",
    "from google_sheet_api import GoogleSheetsUploader\n",
    "from analyzer import run_analysis, run_all_analyses\n",
    "\n",
    "# ========== Setup ========== #\n",
    "BASE_DIR = os.getcwd()\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "CREDENTIAL_PATH = os.path.join(BASE_DIR, \"credential_google_sheets.json\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# ========== Parameters ========== #\n",
    "fetch_mt5 = True\n",
    "STD_MULTIPLIER = 1.96\n",
    "initial_balance = 1000\n",
    "invest_per_week = 100\n",
    "tp_percent = 1.0\n",
    "leverage = 1000\n",
    "min_years_required = 1\n",
    "\n",
    "def main():\n",
    "    # ========== Fetch All Data ========== #\n",
    "    fetcher = YahooFinanceDataFetcher(CONFIG_PATH)\n",
    "    full_df = fetcher.get_data()\n",
    "    symbol_list = full_df[\"Symbol\"].unique()\n",
    "\n",
    "    # ========== Run Single Symbol Analysis ========== #\n",
    "    symbol = \"GOOGL.NAS\"\n",
    "    data, dd_thresh, gain_thresh, df = run_analysis(\n",
    "        df=full_df,\n",
    "        symbol=symbol,\n",
    "        std_multiplier=STD_MULTIPLIER,\n",
    "        plots_dir=PLOTS_DIR,\n",
    "        tp_percent=tp_percent,\n",
    "        leverage=leverage,\n",
    "        coeff=fetcher.coeff_map.get(symbol),\n",
    "        initial_balance=initial_balance,\n",
    "        invest_per_week=invest_per_week,\n",
    "        min_years_required=min_years_required\n",
    "    )\n",
    "    \n",
    "    # ========== Run All Analyses ========== #\n",
    "    df = run_all_analyses(\n",
    "        full_df=full_df,\n",
    "        symbol_list=symbol_list,\n",
    "        std_multiplier=STD_MULTIPLIER,\n",
    "        plots_dir=PLOTS_DIR,\n",
    "        tp_percent=tp_percent,\n",
    "        leverage=leverage,\n",
    "        coeff_map=fetcher.coeff_map,\n",
    "        initial_balance=initial_balance,\n",
    "        invest_per_week=invest_per_week,\n",
    "        min_years_required=min_years_required\n",
    "    )\n",
    "\n",
    "    # ========== Fetch MT5 Live Prices ========== #\n",
    "    if fetch_mt5:\n",
    "        df = MT5DataFetcher(df, min_years_required)\n",
    "\n",
    "    # ========== Upload to Google Sheets ========== #\n",
    "    try:\n",
    "        print(\"\\nüì§ Uploading to Google Sheets...\")\n",
    "        uploader = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "        uploader.upload_dataframe(df, \"Overview\", replace = False)\n",
    "        print(\"‚úÖ Upload successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Upload failed: {e}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching AUDCAD (AUDCAD=X)...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_fetcher import YahooFinanceDataFetcher\n",
    "from mt5_fetcher import MT5DataFetcher\n",
    "from google_sheet_api import GoogleSheetsUploader\n",
    "from analyzer import run_analysis, run_all_analyses\n",
    "\n",
    "# ========== Configuration & Setup ========== #\n",
    "BASE_DIR = os.getcwd()\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "CREDENTIAL_PATH = os.path.join(BASE_DIR, \"credential_google_sheets.json\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# ========== Parameters ========== #\n",
    "fetch_mt5 = True\n",
    "STD_MULTIPLIER = 1.96\n",
    "initial_balance = 1000\n",
    "invest_per_week = 100\n",
    "tp_percent = 1.0\n",
    "leverage = 1000\n",
    "min_years_required = 1\n",
    "\n",
    "def normalize(row):\n",
    "    action = str(row[\"Action\"]).lower()\n",
    "    if action == \"buy\" and pd.notnull(row[\"Worst Drawdown (%)\"]) and row[\"Worst Drawdown (%)\"] != 0:\n",
    "        return row[\"Max_Drawdown\"] * 100 / -row[\"Worst Drawdown (%)\"]\n",
    "    elif action == \"sell\" and pd.notnull(row[\"Max Gain (%)\"]) and row[\"Max Gain (%)\"] != 0:\n",
    "        return row[\"Max_Gain\"] * 100 / row[\"Max Gain (%)\"]\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # ========== Fetch Data ========== #\n",
    "    fetcher = YahooFinanceDataFetcher(CONFIG_PATH)\n",
    "    full_df = fetcher.get_data()\n",
    "    symbol_list = full_df[\"Symbol\"].unique()\n",
    "\n",
    "    # Run single symbol analysis (example: GOOGL.NAS)\n",
    "    symbol = \"GOOGL.NAS\"\n",
    "    run_analysis(\n",
    "        df=full_df,\n",
    "        symbol=symbol,\n",
    "        std_multiplier=STD_MULTIPLIER,\n",
    "        plots_dir=PLOTS_DIR,\n",
    "        tp_percent=tp_percent,\n",
    "        leverage=leverage,\n",
    "        coeff=fetcher.coeff_map.get(symbol),\n",
    "        initial_balance=initial_balance,\n",
    "        invest_per_week=invest_per_week,\n",
    "        min_years_required=min_years_required\n",
    "    )\n",
    "\n",
    "    # Run all analyses\n",
    "    df, df_final = run_all_analyses(\n",
    "        full_df=full_df,\n",
    "        symbol_list=symbol_list,\n",
    "        std_multiplier=STD_MULTIPLIER,\n",
    "        plots_dir=PLOTS_DIR,\n",
    "        tp_percent=tp_percent,\n",
    "        leverage=leverage,\n",
    "        coeff_map=fetcher.coeff_map,\n",
    "        initial_balance=initial_balance,\n",
    "        invest_per_week=invest_per_week,\n",
    "        min_years_required=min_years_required\n",
    "    )\n",
    "\n",
    "    # Optional: Fetch live prices from MT5\n",
    "    if fetch_mt5:\n",
    "        df = MT5DataFetcher(df, min_years_required)\n",
    "\n",
    "    # Fetch Action Data from Google Sheets\n",
    "    sheet_fetcher = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "    df_raw = sheet_fetcher.get_sheet_as_dataframe(\"Forex\")\n",
    "    df_sheet = df_raw.iloc[6:].copy()\n",
    "    df_sheet.columns = df_raw.iloc[5]\n",
    "    df_sheet = df_sheet[[\"Symbol\", \"Type\", \"Action\", \"Max Gain (%)\", \"Worst Drawdown (%)\"]].dropna(subset=[\"Symbol\"]).reset_index(drop=True)\n",
    "\n",
    "    # Merge Action if missing\n",
    "    if \"Action\" not in df_final.columns and \"Action\" in df_sheet.columns:\n",
    "        df_final = df_final.merge(df_sheet[[\"Symbol\", \"Action\"]], on=\"Symbol\", how=\"left\")\n",
    "\n",
    "    # Merge and Normalize\n",
    "    df_final = df_final[[\"Symbol\", \"Datetime\", \"Action\", \"Max_Drawdown\", \"Max_Gain\"]].copy()\n",
    "    df_info = df_sheet[[\"Symbol\", \"Max Gain (%)\", \"Worst Drawdown (%)\"]].drop_duplicates(\"Symbol\")\n",
    "    df_merged = df_final.merge(df_info, on=\"Symbol\", how=\"left\")\n",
    "    df_merged[\"Datetime\"] = pd.to_datetime(df_merged[\"Datetime\"])\n",
    "    df_merged[\"Normalized\"] = df_merged.apply(normalize, axis=1)\n",
    "    df_merged.dropna(subset=[\"Normalized\"], inplace=True)\n",
    "\n",
    "    # Weighting: Half weight if both buy/sell exist\n",
    "    weight_map = (\n",
    "        df_merged.groupby([\"Symbol\", \"Datetime\"])[\"Action\"]\n",
    "        .nunique()\n",
    "        .reset_index(name=\"Action_Count\")\n",
    "    )\n",
    "    weight_map[\"Weight\"] = weight_map[\"Action_Count\"].apply(lambda x: 0.5 if x > 1 else 1.0)\n",
    "    df_merged = df_merged.merge(weight_map[[\"Symbol\", \"Datetime\", \"Weight\"]], on=[\"Symbol\", \"Datetime\"], how=\"left\")\n",
    "    df_merged[\"Weighted_Normalized\"] = df_merged[\"Normalized\"] * df_merged[\"Weight\"]\n",
    "\n",
    "    # Calculate Average Normalized Value by Date\n",
    "    avg_per_date = (\n",
    "        df_merged.groupby(\"Datetime\")[\"Weighted_Normalized\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Weighted_Normalized\": \"Avg_Normalized_Value\"})\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(avg_per_date[\"Datetime\"], avg_per_date[\"Avg_Normalized_Value\"], marker='o', label='Avg Normalized Value')\n",
    "    q5 = avg_per_date[\"Avg_Normalized_Value\"].quantile(0.05)\n",
    "    plt.axhline(y=q5, color='red', linestyle='--', label=f'5th Percentile ({q5:.2f}%)')\n",
    "    plt.title(\"Average Weighted Normalized Drawdown/Gain Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Avg Normalized Value (%)\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Upload to Google Sheets\n",
    "    try:\n",
    "        print(\"\\nüì§ Uploading to Google Sheets...\")\n",
    "        uploader = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "        uploader.upload_dataframe(df, \"Overview\", replace=False)\n",
    "        print(\"‚úÖ Upload successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Upload failed: {e}\")\n",
    "\n",
    "    return avg_per_date\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    avg_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
