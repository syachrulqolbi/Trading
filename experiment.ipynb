{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Fetching data for AUS200 (^AXJO)...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "ðŸ“ˆ Fetching data for ESP35 (^IBEX)...\n",
      "ðŸ“ˆ Fetching data for EUSTX50 (^STOXX50E)...\n",
      "ðŸ“ˆ Fetching data for FRA40 (^FCHI)...\n",
      "ðŸ“ˆ Fetching data for GER40 (^GDAXI)...\n",
      "ðŸ“ˆ Fetching data for JPN225 (^N225)...\n",
      "ðŸ“ˆ Fetching data for NAS100 (^IXIC)...\n",
      "ðŸ“ˆ Fetching data for SPX500 (^GSPC)...\n",
      "ðŸ“ˆ Fetching data for UK100 (^FTSE)...\n",
      "ðŸ“ˆ Fetching data for US30 (^DJI)...\n",
      "\n",
      "ðŸ“Š Symbol Data Summary:\n",
      "        Start_Date   End_Date  Duration_Days\n",
      "Symbol                                      \n",
      "AUS200  2009-01-02 2025-03-13           5914\n",
      "ESP35   2009-01-02 2025-03-13           5914\n",
      "EUSTX50 2009-01-05 2025-03-13           5911\n",
      "FRA40   2009-01-02 2025-03-13           5914\n",
      "GER40   2009-01-02 2025-03-13           5914\n",
      "JPN225  2009-01-05 2025-03-13           5911\n",
      "NAS100  2009-01-02 2025-03-12           5913\n",
      "SPX500  2009-01-02 2025-03-12           5913\n",
      "UK100   2009-01-02 2025-03-13           5914\n",
      "US30    2009-01-02 2025-03-12           5913\n",
      "\n",
      "âœ… Final Summary Table (Unfiltered with Coefficients and Max Price):\n",
      "    Symbol        Date     Price  Max Price    Std  Coefficient\n",
      "0   AUS200  2025-03-13   7749.10    8555.80  22.42         0.06\n",
      "1    ESP35  2025-03-13  12855.40   13373.10  39.60         0.10\n",
      "2  EUSTX50  2025-03-13   5364.68    5540.69  31.60         0.10\n",
      "3    FRA40  2025-03-13   8004.33    8239.99  30.00         0.10\n",
      "4    GER40  2025-03-13  22639.14   23419.48  33.90         0.10\n",
      "5   JPN225  2025-03-13  36790.03   42224.02  44.01         0.01\n",
      "6   NAS100  2025-03-12  17648.45   20173.89  42.93         0.10\n",
      "7   SPX500  2025-03-12   5599.30    6144.15  29.37         0.10\n",
      "8    UK100  2025-03-13   8559.78    8871.30  23.97         0.12\n",
      "9     US30  2025-03-12  41350.93   45014.04  25.43         0.14\n",
      "\n",
      "ðŸ“‰ Analyzing negative gain distributions across symbols...\n",
      "\n",
      "ðŸ” Worst Gain Summary:\n",
      "    Symbol  Worst Gain (%) Date of Worst Gain\n",
      "1    ESP35          -46.18         2011-02-18\n",
      "2  EUSTX50          -33.65         2010-04-14\n",
      "4    GER40          -31.30         2018-10-02\n",
      "6   NAS100          -30.56         2021-07-26\n",
      "8    UK100          -30.26         2018-10-03\n",
      "9     US30          -29.81         2018-10-08\n",
      "3    FRA40          -29.70         2010-04-26\n",
      "5   JPN225          -26.97         2018-09-11\n",
      "0   AUS200          -24.86         2018-10-10\n",
      "7   SPX500          -22.43         2018-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¤ Uploading final summary to Google Sheets...\n",
      "âœ… Cleared all data from sheet: Overview\n",
      "âœ… DataFrame successfully uploaded to Google Sheets: Overview!\n",
      "âœ… Final summary successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "from google_sheet_api import GoogleSheetsUploader\n",
    "\n",
    "# ----------------------------- Define Paths Dynamically -----------------------------\n",
    "BASE_DIR = os.getcwd()\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "CREDENTIAL_PATH = os.path.join(BASE_DIR, \"credential_google_sheets.json\")\n",
    "\n",
    "# ----------------------------- Yahoo Finance Fetcher -----------------------------\n",
    "class YahooFinanceDataFetcher:\n",
    "    def __init__(self, config_file: str) -> None:\n",
    "        with open(config_file, \"r\") as file:\n",
    "            self.config: Dict[str, Any] = yaml.safe_load(file)\n",
    "\n",
    "        self.symbol_map: Dict[str, str] = self.config.get(\"symbols_yfinance\", {})\n",
    "        self.coeff_map: Dict[str, float] = self.config.get(\"symbol_coefficients\", {})\n",
    "        self.daily_period: str = self.config.get(\"daily_period\", \"10y\")\n",
    "        self.daily_interval: str = self.config.get(\"daily_interval\", \"1d\")\n",
    "        self.start_date_filter: str = self.config.get(\"start_date_filter\", \"2009-01-01\")\n",
    "\n",
    "    def fetch_data(self, ticker: str, period: str, interval: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = yf.download(ticker, period=period, interval=interval, progress=False)\n",
    "            if data.empty:\n",
    "                print(f\"âš ï¸ Warning: No data available for '{ticker}'.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error fetching data for '{ticker}': {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def clean_data(self, data: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "        if data.empty:\n",
    "            return data\n",
    "\n",
    "        data = data.reset_index()\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = data.columns.droplevel(1)\n",
    "\n",
    "        data.rename(columns={\"Date\": \"Datetime\", \"datetime\": \"Datetime\"}, inplace=True)\n",
    "        data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "        data = data[data[\"Datetime\"] >= pd.Timestamp(self.start_date_filter, tz=\"UTC\")]\n",
    "        data[\"Datetime\"] = data[\"Datetime\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        for col in numeric_cols:\n",
    "            if col in data.columns:\n",
    "                data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "        data[\"Symbol\"] = symbol\n",
    "        return data[[\"Symbol\", \"Datetime\"] + [col for col in numeric_cols if col in data.columns]]\n",
    "\n",
    "    def process_all_symbols(self) -> Dict[str, pd.DataFrame]:\n",
    "        symbol_data = {}\n",
    "        for symbol, ticker in self.symbol_map.items():\n",
    "            print(f\"ðŸ“ˆ Fetching data for {symbol} ({ticker})...\")\n",
    "            raw_data = self.fetch_data(ticker, self.daily_period, self.daily_interval)\n",
    "            if not raw_data.empty:\n",
    "                cleaned_data = self.clean_data(raw_data, symbol)\n",
    "                symbol_data[symbol] = cleaned_data\n",
    "        if not symbol_data:\n",
    "            print(\"âš ï¸ No data fetched for any symbols.\")\n",
    "        return symbol_data\n",
    "\n",
    "# ----------------------------- Exploratory Data Analysis -----------------------------\n",
    "def EDA(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ Provided DataFrame is empty. No summary to show.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], errors=\"coerce\")\n",
    "    summary = df.groupby(\"Symbol\")[\"Datetime\"].agg(Start_Date=\"min\", End_Date=\"max\")\n",
    "    summary[\"Duration_Days\"] = (summary[\"End_Date\"] - summary[\"Start_Date\"]).dt.days\n",
    "    return summary\n",
    "\n",
    "# ----------------------------- Plotting Utility -----------------------------\n",
    "def plot_price_gain(data, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] >= 0], x='Date', y='Price_Gain_Percentage', label='Gain >= 0%', color='green', alpha=0.6, s=10)\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] < 0], x='Date', y='Price_Gain_Percentage', label='Gain < 0%', color='red', alpha=0.6, s=10)\n",
    "\n",
    "    plt.axhline(avg, color='blue', linestyle='--', label=f'Avg Gain: {avg}%', linewidth=1.5)\n",
    "    plt.axhline(upper_1std, color='purple', linestyle='--', label=f'+1 Std: {upper_1std}%', linewidth=1.2)\n",
    "    plt.axhline(lower_1std, color='orange', linestyle='--', label=f'-1 Std: {lower_1std}%', linewidth=1.2)\n",
    "    plt.axhline(upper_1_97std, color='darkgreen', linestyle='--', label=f'+1.97 Std: {upper_1_97std}%', linewidth=1.2)\n",
    "    plt.axhline(lower_1_97std, color='darkred', linestyle='--', label=f'-1.97 Std: {lower_1_97std}%', linewidth=1.2)\n",
    "\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price Gain Percentage (%)', fontsize=12)\n",
    "    plt.title(f'{symbol} - 365-Day Price Gain % Over Time', fontsize=16, weight='bold')\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"{symbol}.jpg\"), format='jpg', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------------- 365-Day Price Gain Analysis -----------------------------\n",
    "def run_365_day_analysis(data: pd.DataFrame, symbol: str):\n",
    "    data = data.copy()\n",
    "    data['Date'] = pd.to_datetime(data['Datetime'], errors='coerce')\n",
    "    data.sort_values('Date', inplace=True)\n",
    "\n",
    "    data['Price'] = data.get('Close') if 'Close' in data.columns else data.get('Price')\n",
    "    if data['Price'].isnull().all():\n",
    "        raise ValueError(\"No valid 'Price' or 'Close' column found.\")\n",
    "\n",
    "    latest_row = data.dropna(subset=['Price']).iloc[-1]\n",
    "    latest_date = latest_row['Date'].date()\n",
    "    latest_price = round(latest_row['Price'], 2)\n",
    "\n",
    "    data['Price_365_Days_Later'] = data['Price'].shift(-365)\n",
    "    data['Price_Gain_Percentage'] = ((data['Price_365_Days_Later'] - data['Price']) / data['Price'] * 100).round(2)\n",
    "    data.dropna(subset=['Price_Gain_Percentage'], inplace=True)\n",
    "\n",
    "    avg = round(data['Price_Gain_Percentage'].mean(), 2)\n",
    "    std = round(data['Price_Gain_Percentage'].std(), 2)\n",
    "    upper_1std, lower_1std = round(avg + std, 2), round(avg - std, 2)\n",
    "    upper_1_97std, lower_1_97std = round(avg + 1.97 * std, 2), round(avg - 1.97 * std, 2)\n",
    "    std_1_97 = round(1.97 * std, 2)\n",
    "\n",
    "    data['Std'] = std_1_97\n",
    "    plot_price_gain(data, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std)\n",
    "\n",
    "    return data, std_1_97, latest_date, latest_price\n",
    "\n",
    "# ----------------------------- Negative Gain Distribution Analysis -----------------------------\n",
    "def analyze_negative_gain_distribution(symbol_analysis_dict: Dict[str, pd.DataFrame]):\n",
    "    print(\"\\nðŸ“‰ Analyzing negative gain distributions across symbols...\")\n",
    "    worst_gain_rows = []\n",
    "    date_distributions = []\n",
    "\n",
    "    for symbol, df in symbol_analysis_dict.items():\n",
    "        if 'Price_Gain_Percentage' not in df.columns:\n",
    "            continue\n",
    "        worst_row = df.loc[df['Price_Gain_Percentage'].idxmin()]\n",
    "        worst_gain_rows.append({\"Symbol\": symbol, \"Worst Gain (%)\": worst_row['Price_Gain_Percentage'], \"Date of Worst Gain\": worst_row['Date'].date()})\n",
    "        temp_df = pd.DataFrame({\"Symbol\": symbol, \"Negative Gain Dates\": df[df['Price_Gain_Percentage'] < 0]['Date'].dt.date})\n",
    "        date_distributions.append(temp_df)\n",
    "\n",
    "    worst_gain_df = pd.DataFrame(worst_gain_rows).sort_values(\"Worst Gain (%)\")\n",
    "    print(\"\\nðŸ” Worst Gain Summary:\")\n",
    "    print(worst_gain_df)\n",
    "\n",
    "    all_dist_df = pd.concat(date_distributions, ignore_index=True)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.histplot(data=all_dist_df, x=\"Negative Gain Dates\", hue=\"Symbol\", multiple=\"stack\", bins=60)\n",
    "    plt.title(\"ðŸ—“ï¸ Distribution of Dates with Negative Gain % by Symbol\", fontsize=16)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return worst_gain_df\n",
    "\n",
    "# ----------------------------- Main Execution -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    fetcher = YahooFinanceDataFetcher(CONFIG_PATH)\n",
    "    symbol_data_dict = fetcher.process_all_symbols()\n",
    "\n",
    "    all_data_df = pd.concat(symbol_data_dict.values(), ignore_index=True)\n",
    "    summary_df = EDA(all_data_df)\n",
    "    print(\"\\nðŸ“Š Symbol Data Summary:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    final_summary_rows = []\n",
    "    symbol_analysis_dict = {}\n",
    "\n",
    "    for symbol, df in symbol_data_dict.items():\n",
    "        annotated_df, std_value, date, price = run_365_day_analysis(df, symbol)\n",
    "        symbol_analysis_dict[symbol] = annotated_df\n",
    "        coeff = fetcher.coeff_map.get(symbol)\n",
    "        max_price = round(df[\"Close\"].max(), 2) if \"Close\" in df.columns else None\n",
    "        final_summary_rows.append({\"Symbol\": symbol, \"Date\": date, \"Price\": price, \"Max Price\": max_price, \"Std\": std_value, \"Coefficient\": coeff})\n",
    "\n",
    "    final_summary_df = pd.DataFrame(final_summary_rows)\n",
    "    print(\"\\nâœ… Final Summary Table (Unfiltered with Coefficients and Max Price):\")\n",
    "    print(final_summary_df)\n",
    "\n",
    "    worst_gain_df = analyze_negative_gain_distribution(symbol_analysis_dict)\n",
    "\n",
    "    try:\n",
    "        print(\"\\nðŸ“¤ Uploading final summary to Google Sheets...\")\n",
    "        gs_uploader = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "        gs_uploader.upload_dataframe(final_summary_df, \"Overview\")\n",
    "        print(\"âœ… Final summary successfully uploaded to Google Sheets!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to upload to Google Sheets: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
