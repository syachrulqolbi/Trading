{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Fetching data for AUS200 (^AXJO)...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "üìà Fetching data for ESP35 (^IBEX)...\n",
      "üìà Fetching data for EUSTX50 (^STOXX50E)...\n",
      "üìà Fetching data for FRA40 (^FCHI)...\n",
      "üìà Fetching data for GER40 (^GDAXI)...\n",
      "üìà Fetching data for JPN225 (^N225)...\n",
      "üìà Fetching data for NAS100 (^IXIC)...\n",
      "üìà Fetching data for SPX500 (^GSPC)...\n",
      "üìà Fetching data for UK100 (^FTSE)...\n",
      "üìà Fetching data for US30 (^DJI)...\n",
      "\n",
      "üìä Symbol Data Summary:\n",
      "        Start_Date   End_Date  Duration_Days\n",
      "Symbol                                      \n",
      "AUS200  2009-01-02 2025-03-13           5914\n",
      "ESP35   2009-01-02 2025-03-13           5914\n",
      "EUSTX50 2009-01-05 2025-03-13           5911\n",
      "FRA40   2009-01-02 2025-03-13           5914\n",
      "GER40   2009-01-02 2025-03-13           5914\n",
      "JPN225  2009-01-05 2025-03-13           5911\n",
      "NAS100  2009-01-02 2025-03-12           5913\n",
      "SPX500  2009-01-02 2025-03-12           5913\n",
      "UK100   2009-01-02 2025-03-13           5914\n",
      "US30    2009-01-02 2025-03-12           5913\n",
      "\n",
      "‚úÖ Final Summary Table (Unfiltered with Coefficients and Max Price):\n",
      "    Symbol        Date     Price  Max Price    Std  Coefficient\n",
      "0   AUS200  2025-03-13   7749.10    8555.80  22.42         0.06\n",
      "1    ESP35  2025-03-13  12855.40   13373.10  39.60         0.10\n",
      "2  EUSTX50  2025-03-13   5364.68    5540.69  31.60         0.10\n",
      "3    FRA40  2025-03-13   8004.33    8239.99  30.00         0.10\n",
      "4    GER40  2025-03-13  22639.14   23419.48  33.90         0.10\n",
      "5   JPN225  2025-03-13  36790.03   42224.02  44.01         0.01\n",
      "6   NAS100  2025-03-12  17648.45   20173.89  42.93         0.10\n",
      "7   SPX500  2025-03-12   5599.30    6144.15  29.37         0.10\n",
      "8    UK100  2025-03-13   8559.78    8871.30  23.97         0.12\n",
      "9     US30  2025-03-12  41350.93   45014.04  25.43         0.14\n",
      "\n",
      "üìâ Analyzing negative gain distributions across symbols...\n",
      "\n",
      "üîç Worst Gain Summary:\n",
      "    Symbol  Worst Gain (%) Date of Worst Gain\n",
      "1    ESP35          -46.18         2011-02-18\n",
      "2  EUSTX50          -33.65         2010-04-14\n",
      "4    GER40          -31.30         2018-10-02\n",
      "6   NAS100          -30.56         2021-07-26\n",
      "8    UK100          -30.26         2018-10-03\n",
      "9     US30          -29.81         2018-10-08\n",
      "3    FRA40          -29.70         2010-04-26\n",
      "5   JPN225          -26.97         2018-09-11\n",
      "0   AUS200          -24.86         2018-10-10\n",
      "7   SPX500          -22.43         2018-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:161: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 128467 (\\N{SPIRAL CALENDAR PAD}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Glyph 65039 (\\N{VARIATION SELECTOR-16}) missing from font(s) Arial.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
      "C:\\Users\\syahr\\AppData\\Local\\Temp\\ipykernel_4280\\4205951038.py:162: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ Uploading final summary to Google Sheets...\n",
      "‚úÖ Cleared all data from sheet: Overview\n",
      "‚úÖ DataFrame successfully uploaded to Google Sheets: Overview!\n",
      "‚úÖ Final summary successfully uploaded to Google Sheets!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "from google_sheet_api import GoogleSheetsUploader\n",
    "\n",
    "# ----------------------------- Define Paths Dynamically -----------------------------\n",
    "BASE_DIR = os.getcwd()\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "CREDENTIAL_PATH = os.path.join(BASE_DIR, \"credential_google_sheets.json\")\n",
    "\n",
    "# ----------------------------- Yahoo Finance Fetcher -----------------------------\n",
    "class YahooFinanceDataFetcher:\n",
    "    def __init__(self, config_file: str) -> None:\n",
    "        with open(config_file, \"r\") as file:\n",
    "            self.config: Dict[str, Any] = yaml.safe_load(file)\n",
    "\n",
    "        self.symbol_map: Dict[str, str] = self.config.get(\"symbols_yfinance\", {})\n",
    "        self.coeff_map: Dict[str, float] = self.config.get(\"symbol_coefficients\", {})\n",
    "        self.daily_period: str = self.config.get(\"daily_period\", \"10y\")\n",
    "        self.daily_interval: str = self.config.get(\"daily_interval\", \"1d\")\n",
    "        self.start_date_filter: str = self.config.get(\"start_date_filter\", \"2009-01-01\")\n",
    "\n",
    "    def fetch_data(self, ticker: str, period: str, interval: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            data = yf.download(ticker, period=period, interval=interval, progress=False)\n",
    "            if data.empty:\n",
    "                print(f\"‚ö†Ô∏è Warning: No data available for '{ticker}'.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching data for '{ticker}': {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def clean_data(self, data: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "        if data.empty:\n",
    "            return data\n",
    "\n",
    "        data = data.reset_index()\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = data.columns.droplevel(1)\n",
    "\n",
    "        data.rename(columns={\"Date\": \"Datetime\", \"datetime\": \"Datetime\"}, inplace=True)\n",
    "        data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "        data = data[data[\"Datetime\"] >= pd.Timestamp(self.start_date_filter, tz=\"UTC\")]\n",
    "        data[\"Datetime\"] = data[\"Datetime\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        for col in numeric_cols:\n",
    "            if col in data.columns:\n",
    "                data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "        data[\"Symbol\"] = symbol\n",
    "        return data[[\"Symbol\", \"Datetime\"] + [col for col in numeric_cols if col in data.columns]]\n",
    "\n",
    "    def process_all_symbols(self) -> Dict[str, pd.DataFrame]:\n",
    "        symbol_data = {}\n",
    "        for symbol, ticker in self.symbol_map.items():\n",
    "            print(f\"üìà Fetching data for {symbol} ({ticker})...\")\n",
    "            raw_data = self.fetch_data(ticker, self.daily_period, self.daily_interval)\n",
    "            if not raw_data.empty:\n",
    "                cleaned_data = self.clean_data(raw_data, symbol)\n",
    "                symbol_data[symbol] = cleaned_data\n",
    "        if not symbol_data:\n",
    "            print(\"‚ö†Ô∏è No data fetched for any symbols.\")\n",
    "        return symbol_data\n",
    "\n",
    "# ----------------------------- Exploratory Data Analysis -----------------------------\n",
    "def EDA(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è Provided DataFrame is empty. No summary to show.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], errors=\"coerce\")\n",
    "    summary = df.groupby(\"Symbol\")[\"Datetime\"].agg(Start_Date=\"min\", End_Date=\"max\")\n",
    "    summary[\"Duration_Days\"] = (summary[\"End_Date\"] - summary[\"Start_Date\"]).dt.days\n",
    "    return summary\n",
    "\n",
    "# ----------------------------- Plotting Utility -----------------------------\n",
    "def plot_price_gain(data, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] >= 0], x='Date', y='Price_Gain_Percentage', label='Gain >= 0%', color='green', alpha=0.6, s=10)\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] < 0], x='Date', y='Price_Gain_Percentage', label='Gain < 0%', color='red', alpha=0.6, s=10)\n",
    "\n",
    "    plt.axhline(avg, color='blue', linestyle='--', label=f'Avg Gain: {avg}%', linewidth=1.5)\n",
    "    plt.axhline(upper_1std, color='purple', linestyle='--', label=f'+1 Std: {upper_1std}%', linewidth=1.2)\n",
    "    plt.axhline(lower_1std, color='orange', linestyle='--', label=f'-1 Std: {lower_1std}%', linewidth=1.2)\n",
    "    plt.axhline(upper_1_97std, color='darkgreen', linestyle='--', label=f'+1.97 Std: {upper_1_97std}%', linewidth=1.2)\n",
    "    plt.axhline(lower_1_97std, color='darkred', linestyle='--', label=f'-1.97 Std: {lower_1_97std}%', linewidth=1.2)\n",
    "\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price Gain Percentage (%)', fontsize=12)\n",
    "    plt.title(f'{symbol} - 365-Day Price Gain % Over Time', fontsize=16, weight='bold')\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"{symbol}.jpg\"), format='jpg', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------------- 365-Day Price Gain Analysis -----------------------------\n",
    "def run_365_day_analysis(data: pd.DataFrame, symbol: str):\n",
    "    data = data.copy()\n",
    "    data['Date'] = pd.to_datetime(data['Datetime'], errors='coerce')\n",
    "    data.sort_values('Date', inplace=True)\n",
    "\n",
    "    data['Price'] = data.get('Close') if 'Close' in data.columns else data.get('Price')\n",
    "    if data['Price'].isnull().all():\n",
    "        raise ValueError(\"No valid 'Price' or 'Close' column found.\")\n",
    "\n",
    "    latest_row = data.dropna(subset=['Price']).iloc[-1]\n",
    "    latest_date = latest_row['Date'].date()\n",
    "    latest_price = round(latest_row['Price'], 2)\n",
    "\n",
    "    data['Price_365_Days_Later'] = data['Price'].shift(-365)\n",
    "    data['Price_Gain_Percentage'] = ((data['Price_365_Days_Later'] - data['Price']) / data['Price'] * 100).round(2)\n",
    "    data.dropna(subset=['Price_Gain_Percentage'], inplace=True)\n",
    "\n",
    "    avg = round(data['Price_Gain_Percentage'].mean(), 2)\n",
    "    std = round(data['Price_Gain_Percentage'].std(), 2)\n",
    "    upper_1std, lower_1std = round(avg + std, 2), round(avg - std, 2)\n",
    "    upper_1_97std, lower_1_97std = round(avg + 1.97 * std, 2), round(avg - 1.97 * std, 2)\n",
    "    std_1_97 = round(1.97 * std, 2)\n",
    "\n",
    "    data['Std'] = std_1_97\n",
    "    plot_price_gain(data, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std)\n",
    "\n",
    "    return data, std_1_97, latest_date, latest_price\n",
    "\n",
    "# ----------------------------- Negative Gain Distribution Analysis -----------------------------\n",
    "def analyze_negative_gain_distribution(symbol_analysis_dict: Dict[str, pd.DataFrame]):\n",
    "    print(\"\\nüìâ Analyzing negative gain distributions across symbols...\")\n",
    "    worst_gain_rows = []\n",
    "    date_distributions = []\n",
    "\n",
    "    for symbol, df in symbol_analysis_dict.items():\n",
    "        if 'Price_Gain_Percentage' not in df.columns:\n",
    "            continue\n",
    "        worst_row = df.loc[df['Price_Gain_Percentage'].idxmin()]\n",
    "        worst_gain_rows.append({\"Symbol\": symbol, \"Worst Gain (%)\": worst_row['Price_Gain_Percentage'], \"Date of Worst Gain\": worst_row['Date'].date()})\n",
    "        temp_df = pd.DataFrame({\"Symbol\": symbol, \"Negative Gain Dates\": df[df['Price_Gain_Percentage'] < 0]['Date'].dt.date})\n",
    "        date_distributions.append(temp_df)\n",
    "\n",
    "    worst_gain_df = pd.DataFrame(worst_gain_rows).sort_values(\"Worst Gain (%)\")\n",
    "    print(\"\\nüîç Worst Gain Summary:\")\n",
    "    print(worst_gain_df)\n",
    "\n",
    "    all_dist_df = pd.concat(date_distributions, ignore_index=True)\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.histplot(data=all_dist_df, x=\"Negative Gain Dates\", hue=\"Symbol\", multiple=\"stack\", bins=60)\n",
    "    plt.title(\"üóìÔ∏è Distribution of Dates with Negative Gain % by Symbol\", fontsize=16)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, \"negative_gain_distribution.jpg\"), format='jpg', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return worst_gain_df\n",
    "\n",
    "# ----------------------------- Main Execution -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    fetcher = YahooFinanceDataFetcher(CONFIG_PATH)\n",
    "    symbol_data_dict = fetcher.process_all_symbols()\n",
    "\n",
    "    all_data_df = pd.concat(symbol_data_dict.values(), ignore_index=True)\n",
    "    summary_df = EDA(all_data_df)\n",
    "    print(\"\\nüìä Symbol Data Summary:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    final_summary_rows = []\n",
    "    symbol_analysis_dict = {}\n",
    "\n",
    "    for symbol, df in symbol_data_dict.items():\n",
    "        annotated_df, std_value, date, price = run_365_day_analysis(df, symbol)\n",
    "        symbol_analysis_dict[symbol] = annotated_df\n",
    "        coeff = fetcher.coeff_map.get(symbol)\n",
    "        max_price = round(df[\"Close\"].max(), 2) if \"Close\" in df.columns else None\n",
    "        final_summary_rows.append({\"Symbol\": symbol, \"Date\": date, \"Price\": price, \"Max Price\": max_price, \"Std\": std_value, \"Coefficient\": coeff})\n",
    "\n",
    "    final_summary_df = pd.DataFrame(final_summary_rows)\n",
    "    print(\"\\n‚úÖ Final Summary Table (Unfiltered with Coefficients and Max Price):\")\n",
    "    print(final_summary_df)\n",
    "\n",
    "    worst_gain_df = analyze_negative_gain_distribution(symbol_analysis_dict)\n",
    "\n",
    "    try:\n",
    "        print(\"\\nüì§ Uploading final summary to Google Sheets...\")\n",
    "        gs_uploader = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "        gs_uploader.upload_dataframe(final_summary_df, \"Overview\")\n",
    "        print(\"‚úÖ Final summary successfully uploaded to Google Sheets!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to upload to Google Sheets: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
