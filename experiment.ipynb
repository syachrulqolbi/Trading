{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Fetching AUS200 (^AXJO)...\n",
      "📈 Fetching ESP35 (^IBEX)...\n",
      "📈 Fetching EUSTX50 (^STOXX50E)...\n",
      "📈 Fetching FRA40 (^FCHI)...\n",
      "📈 Fetching GER40 (^GDAXI)...\n",
      "📈 Fetching JPN225 (^N225)...\n",
      "📈 Fetching NAS100 (^IXIC)...\n",
      "📈 Fetching SPX500 (^GSPC)...\n",
      "📈 Fetching UK100 (^FTSE)...\n",
      "📈 Fetching US30 (^DJI)...\n",
      "📈 Fetching BAC.NYSE (BAC)...\n",
      "📈 Fetching GS.NYSE (GS)...\n",
      "📈 Fetching JPM.NYSE (JPM)...\n",
      "📈 Fetching MS.NYSE (MS)...\n",
      "📈 Fetching WFC.NYSE (WFC)...\n",
      "📈 Fetching CBA.ASX (CBA.AX)...\n",
      "📈 Fetching NAB.ASX (NAB.AX)...\n",
      "📈 Fetching BNP.EPA (BNP.PA)...\n",
      "📈 Fetching BARC.LSE (BARC.L)...\n",
      "📈 Fetching HSBA.LSE (HSBA.L)...\n",
      "📈 Fetching ISP.MIL (ISP.MI)...\n",
      "📈 Fetching UCG.MIL (UCG.MI)...\n",
      "📈 Fetching BBVA.BM (BBVA.MC)...\n",
      "📈 Fetching CABK.BM (CABK.MC)...\n",
      "📈 Fetching SAN.BM (SAN.MC)...\n",
      "\n",
      "📊 EDA Summary:\n",
      "         Start_Date   End_Date  Duration_Days\n",
      "Symbol                                       \n",
      "AUS200   1995-03-14 2025-03-14          10958\n",
      "BAC.NYSE 1995-03-15 2025-03-14          10957\n",
      "BARC.LSE 1995-03-14 2025-03-14          10958\n",
      "BBVA.BM  2000-01-03 2025-03-14           9202\n",
      "BNP.EPA  1995-03-14 2025-03-14          10958\n",
      "CABK.BM  2007-10-10 2025-03-14           6365\n",
      "CBA.ASX  1995-03-14 2025-03-14          10958\n",
      "ESP35    1995-03-14 2025-03-14          10958\n",
      "EUSTX50  2007-03-30 2025-03-14           6559\n",
      "FRA40    1995-03-14 2025-03-14          10958\n",
      "GER40    1995-03-14 2025-03-14          10958\n",
      "GS.NYSE  1999-05-04 2025-03-14           9446\n",
      "HSBA.LSE 1995-03-14 2025-03-14          10958\n",
      "ISP.MIL  1995-03-24 2025-03-14          10948\n",
      "JPM.NYSE 1995-03-15 2025-03-14          10957\n",
      "JPN225   1995-03-14 2025-03-14          10958\n",
      "MS.NYSE  1995-03-15 2025-03-14          10957\n",
      "NAB.ASX  1995-03-14 2025-03-14          10958\n",
      "NAS100   1995-03-15 2025-03-14          10957\n",
      "SAN.BM   2000-01-03 2025-03-14           9202\n",
      "SPX500   1995-03-15 2025-03-14          10957\n",
      "UCG.MIL  2000-01-03 2025-03-14           9202\n",
      "UK100    1995-03-14 2025-03-14          10958\n",
      "US30     1995-03-15 2025-03-14          10957\n",
      "WFC.NYSE 1995-03-15 2025-03-14          10957\n",
      "\n",
      "✅ Final Summary:\n",
      "      Symbol        Date     Price  Max Price    Std  Coefficient  \\\n",
      "0     AUS200  2025-03-14   7789.70    8555.80  21.75         0.06   \n",
      "1      ESP35  2025-03-14  13005.20   13373.10  39.57         0.10   \n",
      "2    EUSTX50  2025-03-14   5404.18    5540.69  33.06         0.10   \n",
      "3      FRA40  2025-03-14   8028.28    8239.99  35.89         0.10   \n",
      "4      GER40  2025-03-14  22986.82   23419.48  35.63         0.10   \n",
      "5     JPN225  2025-03-14  37053.10   42224.02  42.32         0.01   \n",
      "6     NAS100  2025-03-14  17754.09   20173.89  36.80         0.10   \n",
      "7     SPX500  2025-03-14   5638.94    6144.15  26.89         0.10   \n",
      "8      UK100  2025-03-14   8632.30    8871.30  26.83         0.12   \n",
      "9       US30  2025-03-14  41488.19   45014.04  22.16         0.14   \n",
      "10  BAC.NYSE  2025-03-14     40.89      47.44  59.93         1.00   \n",
      "11   GS.NYSE  2025-03-14    541.41     668.87  47.39         1.00   \n",
      "12  JPM.NYSE  2025-03-14    232.44     279.95  39.86         1.00   \n",
      "13   MS.NYSE  2025-03-14    115.34     141.08  61.52         1.00   \n",
      "14  WFC.NYSE  2025-03-14     70.85      81.02  31.39         1.00   \n",
      "15   CBA.ASX  2025-03-14    142.36     164.41  20.70         1.00   \n",
      "16   NAB.ASX  2025-03-14     33.30      41.24  29.83         1.00   \n",
      "17   BNP.EPA  2025-03-14     75.72      77.17  43.79         1.00   \n",
      "18  BARC.LSE  2025-03-14    294.75     311.30  56.33         1.00   \n",
      "19  HSBA.LSE  2025-03-14    870.00     905.95  41.95         1.00   \n",
      "20   ISP.MIL  2025-03-14      4.80       4.89  65.03         1.00   \n",
      "21   UCG.MIL  2025-03-14     52.70      54.58  98.43         1.00   \n",
      "22   BBVA.BM  2025-03-14     13.18      13.18  55.25         1.00   \n",
      "23   CABK.BM  2025-03-14      7.02       7.09  63.04         1.00   \n",
      "24    SAN.BM  2025-03-14      6.21       6.31  56.84         1.00   \n",
      "\n",
      "    Annual Return (Simulated)  \n",
      "0                      227.07  \n",
      "1                       93.39  \n",
      "2                      110.36  \n",
      "3                      106.87  \n",
      "4                      105.43  \n",
      "5                       84.59  \n",
      "6                      101.37  \n",
      "7                      159.52  \n",
      "8                      164.44  \n",
      "9                      223.59  \n",
      "10                      53.69  \n",
      "11                      72.82  \n",
      "12                      93.90  \n",
      "13                      51.85  \n",
      "14                     132.10  \n",
      "15                     254.64  \n",
      "16                     140.42  \n",
      "17                      84.02  \n",
      "18                      58.93  \n",
      "19                      86.51  \n",
      "20                      48.30  \n",
      "21                      27.82  \n",
      "22                      58.92  \n",
      "23                      45.62  \n",
      "24                      55.03  \n",
      "\n",
      "📤 Uploading to Google Sheets...\n",
      "✅ Cleared all data from sheet: Overview\n",
      "✅ DataFrame successfully uploaded to Google Sheets: Overview!\n",
      "✅ Upload successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "from google_sheet_api import GoogleSheetsUploader\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# === Configuration and Directory Setup ===\n",
    "BASE_DIR = os.getcwd()\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "PLOTS_DIR = os.path.join(BASE_DIR, \"plots\")\n",
    "CREDENTIAL_PATH = os.path.join(BASE_DIR, \"credential_google_sheets.json\")\n",
    "\n",
    "\n",
    "def cleanup_existing_plots(plot_name: str):\n",
    "    \"\"\"Delete existing plot image if exists.\"\"\"\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    plot_path = os.path.join(PLOTS_DIR, plot_name)\n",
    "    if os.path.exists(plot_path):\n",
    "        os.remove(plot_path)\n",
    "\n",
    "\n",
    "# === Yahoo Finance Data Fetcher Class ===\n",
    "class YahooFinanceDataFetcher:\n",
    "    def __init__(self, config_file: str) -> None:\n",
    "        with open(config_file, \"r\") as file:\n",
    "            self.config: Dict[str, Any] = yaml.safe_load(file)\n",
    "        self.symbol_map = self.config.get(\"symbols_yfinance\", {})\n",
    "        self.coeff_map = self.config.get(\"symbol_coefficients\", {})\n",
    "        self.daily_period = self.config.get(\"daily_period\", \"10y\")\n",
    "        self.daily_interval = self.config.get(\"daily_interval\", \"1d\")\n",
    "        self.std_multiplier = float(self.config.get(\"std_multiplier\", 1.97))\n",
    "\n",
    "    def fetch_data(self, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Download historical price data using yfinance.\"\"\"\n",
    "        try:\n",
    "            data = yf.download(ticker, period=self.daily_period, interval=self.daily_interval, progress=False)\n",
    "            if data.empty:\n",
    "                print(f\"⚠️ No data for '{ticker}'.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error fetching '{ticker}': {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def clean_data(self, data: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "        \"\"\"Clean and standardize data format.\"\"\"\n",
    "        if data.empty:\n",
    "            return data\n",
    "        data = data.reset_index()\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = data.columns.droplevel(1)\n",
    "        data.rename(columns={\"Date\": \"Datetime\", \"datetime\": \"Datetime\"}, inplace=True)\n",
    "        data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"], errors=\"coerce\", utc=True).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "            if col in data.columns:\n",
    "                data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "        data[\"Symbol\"] = symbol\n",
    "        return data[[\"Symbol\", \"Datetime\"] + [col for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"] if col in data.columns]]\n",
    "\n",
    "    def process_all_symbols(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Fetch and clean data for all configured symbols.\"\"\"\n",
    "        symbol_data = {}\n",
    "        for symbol, ticker in self.symbol_map.items():\n",
    "            print(f\"📈 Fetching {symbol} ({ticker})...\")\n",
    "            raw_data = self.fetch_data(ticker)\n",
    "            if not raw_data.empty:\n",
    "                symbol_data[symbol] = self.clean_data(raw_data, symbol)\n",
    "        if not symbol_data:\n",
    "            print(\"⚠️ No data fetched for any symbols.\")\n",
    "        return symbol_data\n",
    "\n",
    "\n",
    "# === Exploratory Data Analysis (EDA) ===\n",
    "def perform_eda(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Summary of available date range and duration for each symbol.\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"⚠️ DataFrame is empty. Skipping EDA summary.\")\n",
    "        return pd.DataFrame()\n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], errors=\"coerce\")\n",
    "    summary = df.groupby(\"Symbol\")[\"Datetime\"].agg(Start_Date=\"min\", End_Date=\"max\")\n",
    "    summary[\"Duration_Days\"] = (summary[\"End_Date\"] - summary[\"Start_Date\"]).dt.days\n",
    "    return summary\n",
    "\n",
    "def plot_price_gain(data, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] >= 0], x='Date', y='Price_Gain_Percentage', label='Gain ≥ 0%', color='green', alpha=0.6, s=10)\n",
    "    sns.scatterplot(data=data[data['Price_Gain_Percentage'] < 0], x='Date', y='Price_Gain_Percentage', label='Gain < 0%', color='red', alpha=0.6, s=10)\n",
    "\n",
    "    plt.axhline(avg, color='blue', linestyle='--', label=f'Avg Gain: {avg}%')\n",
    "    plt.axhline(upper_1std, color='purple', linestyle='--', label=f'+1 Std: {upper_1std}%')\n",
    "    plt.axhline(lower_1std, color='orange', linestyle='--', label=f'-1 Std: {lower_1std}%')\n",
    "    plt.axhline(upper_1_97std, color='darkgreen', linestyle='--', label=f'+1.97 Std: {upper_1_97std}%')\n",
    "    plt.axhline(lower_1_97std, color='darkred', linestyle='--', label=f'-1.97 Std: {lower_1_97std}%')\n",
    "\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('365-Day Gain Percentage (%)', fontsize=12)\n",
    "    plt.title(f'{symbol} - 365-Day Price Gain % Over Time', fontsize=16)\n",
    "    plt.legend(loc='upper center')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"{symbol}_gain_plot.jpg\"), format='jpg', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === 365-Day Gain Analysis ===\n",
    "def analyze_365_day_gain(data: pd.DataFrame, symbol: str, std_multiplier: float):\n",
    "    \"\"\"Calculate average gain and adjusted standard deviation (excluding outliers above +2.576 std).\"\"\"\n",
    "    data = data.copy()\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Datetime\"], errors=\"coerce\")\n",
    "    data.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    data[\"Price\"] = data.get(\"Close\", data.get(\"Price\"))\n",
    "    if data[\"Price\"].isnull().all():\n",
    "        print(f\"⚠️ Skipping {symbol}: 'Price' column is entirely null.\")\n",
    "        return data, None, None, None, None, None\n",
    "\n",
    "    latest_row = data.dropna(subset=[\"Price\"]).iloc[-1]\n",
    "    latest_date = latest_row[\"Date\"].date()\n",
    "    latest_price = round(latest_row[\"Price\"], 2)\n",
    "\n",
    "    data[\"Price_365_Days_Later\"] = data[\"Price\"].shift(-365)\n",
    "    data[\"Price_Gain_Percentage\"] = ((data[\"Price_365_Days_Later\"] - data[\"Price\"]) / data[\"Price\"]) * 100\n",
    "    data.dropna(subset=[\"Price_Gain_Percentage\"], inplace=True)\n",
    "    data[\"Price_Gain_Percentage\"] = data[\"Price_Gain_Percentage\"].round(2)\n",
    "\n",
    "    avg = round(data[\"Price_Gain_Percentage\"].mean(), 2)\n",
    "\n",
    "    # ✅ Remove outliers > +2.576 std for std calculation only\n",
    "    z_scores = zscore(data[\"Price_Gain_Percentage\"])\n",
    "    filtered_data = data[(z_scores <= std_multiplier)]  # keeping everything within Z <= 2.576\n",
    "    filtered_std = round(filtered_data[\"Price_Gain_Percentage\"].std(), 2)\n",
    "\n",
    "    upper = round(avg + std_multiplier * filtered_std, 2)\n",
    "    lower = round(avg - std_multiplier * filtered_std, 2)\n",
    "\n",
    "    return data, avg, upper, lower, latest_date, latest_price\n",
    "\n",
    "\n",
    "# === Weekly Backtest Simulation ===\n",
    "def backtest_weekly_investment(df: pd.DataFrame, initial_balance: float, invest_per_week: float, tp_percent: float,\n",
    "                                leverage: float, coeff: float, std: float, start_date: str = None, end_date: str = None):\n",
    "    \"\"\"Simulate a weekly investment portfolio with take profit threshold.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Datetime\"]).dt.date\n",
    "    df = df.sort_values(\"Date\")\n",
    "\n",
    "    if start_date:\n",
    "        df = df[df[\"Date\"] >= pd.to_datetime(start_date).date()]\n",
    "    if end_date:\n",
    "        df = df[df[\"Date\"] <= pd.to_datetime(end_date).date()]\n",
    "\n",
    "    df[\"Week\"] = pd.to_datetime(df[\"Date\"]).dt.to_period(\"W\").apply(lambda r: r.start_time.date())\n",
    "    weekly_df = df.groupby(\"Week\").first().reset_index()\n",
    "    weekly_df = weekly_df[weekly_df[\"Close\"].notnull()]\n",
    "\n",
    "    cash_invest = cash_saving = cash_saving_interest = initial_balance\n",
    "    list_trade_price, list_lot_size = [], []\n",
    "    portfolio_history = []\n",
    "\n",
    "    for _, row in weekly_df.iterrows():\n",
    "        price = row[\"Close\"]\n",
    "        if pd.isna(price) or price <= 0:\n",
    "            continue\n",
    "\n",
    "        value_divider = std * price * coeff\n",
    "        lot_size = max(round(cash_invest / value_divider, 2), 0.01)\n",
    "        profit_tp = 0.0\n",
    "\n",
    "        if not list_trade_price:\n",
    "            list_trade_price.append(price)\n",
    "            list_lot_size.append(lot_size)\n",
    "            cash_invest += invest_per_week\n",
    "        else:\n",
    "            previous_price = list_trade_price[-1]\n",
    "            if previous_price <= price * (1 + tp_percent / 100.0):\n",
    "                avg_trade_price = sum(p * l for p, l in zip(list_trade_price, list_lot_size)) / sum(list_lot_size)\n",
    "                profit_tp = avg_trade_price * sum(list_lot_size) * (tp_percent / 100.0) * coeff * 100 * leverage / 1000\n",
    "                cash_invest += invest_per_week + profit_tp\n",
    "                list_trade_price, list_lot_size = [], []\n",
    "            else:\n",
    "                list_trade_price.append(price)\n",
    "                list_lot_size.append(lot_size)\n",
    "                cash_invest += invest_per_week\n",
    "                avg_trade_price = sum(p * l for p, l in zip(list_trade_price, list_lot_size)) / sum(list_lot_size)\n",
    "                if price < avg_trade_price * (1 - std / 100.0):\n",
    "                    print(f\"🚨 {df['Symbol'].iloc[0] if 'Symbol' in df.columns else ''}: Price dropped below avg trade price - std at {row['Week']}. Portfolio wiped out.\")\n",
    "                    cash_invest = 0\n",
    "                    break\n",
    "\n",
    "        cash_saving += invest_per_week\n",
    "        weekly_interest_rate = (1 + 0.05) ** (1 / 52) - 1\n",
    "        cash_saving_interest = (cash_saving_interest + invest_per_week) * (1 + weekly_interest_rate)\n",
    "\n",
    "        portfolio_history.append({\n",
    "            \"Week\": row[\"Week\"], \"Close_Price\": price, \"Profit_TP\": round(profit_tp, 2),\n",
    "            \"Cash_Invest\": cash_invest, \"Cash_Saving\": cash_saving,\n",
    "            \"Cash_Saving_Interest\": cash_saving_interest\n",
    "        })\n",
    "\n",
    "    portfolio_df = pd.DataFrame(portfolio_history)\n",
    "\n",
    "    def calculate_adjusted_return(df: pd.DataFrame, value_col: str) -> float:\n",
    "        if df.empty or value_col not in df.columns:\n",
    "            return 0.0\n",
    "        years = (df[\"Week\"].iloc[-1] - df[\"Week\"].iloc[0]).days / 365.25\n",
    "        if years <= 0: return 0.0\n",
    "        total_contribution = initial_balance + invest_per_week * len(df)\n",
    "        final_value = df[value_col].iloc[-1]\n",
    "        return round(((final_value / total_contribution) ** (1 / years) - 1) * 100, 2)\n",
    "\n",
    "    ar_invest = calculate_adjusted_return(portfolio_df, \"Cash_Invest\")\n",
    "    ar_saving = calculate_adjusted_return(portfolio_df, \"Cash_Saving\")\n",
    "    ar_saving_interest = calculate_adjusted_return(portfolio_df, \"Cash_Saving_Interest\")\n",
    "\n",
    "    # === Save Plot ===\n",
    "    symbol_title = df[\"Symbol\"].iloc[0] if \"Symbol\" in df.columns else \"Symbol\"\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(portfolio_df['Week'], portfolio_df['Cash_Invest'], label=f'Investment (TP {tp_percent}% | AR {ar_invest}%)', linestyle='-.')\n",
    "    plt.plot(portfolio_df['Week'], portfolio_df['Cash_Saving'], label=f'Saving (AR {ar_saving}%)', linestyle='--')\n",
    "    plt.plot(portfolio_df['Week'], portfolio_df['Cash_Saving_Interest'], label=f'Saving +5% Interest (AR {ar_saving_interest}%)', linestyle=':')\n",
    "    plt.title(f'{symbol_title} - Weekly Investment vs Saving', fontsize=14)\n",
    "    plt.xlabel('Week'); plt.ylabel('Total Value ($)')\n",
    "    plt.legend(); plt.xticks(rotation=45); plt.grid(True); plt.tight_layout()\n",
    "\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "    plot_path = os.path.join(PLOTS_DIR, f\"{symbol_title}_investment_plot.jpg\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    return portfolio_df, ar_invest, ar_saving, ar_saving_interest\n",
    "\n",
    "\n",
    "# === Main Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    fetcher = YahooFinanceDataFetcher(CONFIG_PATH)\n",
    "    symbol_data = fetcher.process_all_symbols()\n",
    "    full_df = pd.concat(symbol_data.values(), ignore_index=True)\n",
    "\n",
    "    print(\"\\n📊 EDA Summary:\")\n",
    "    print(perform_eda(full_df))\n",
    "\n",
    "    final_summary, analyzed_data = [], {}\n",
    "    for symbol, df in symbol_data.items():\n",
    "        annotated_df, avg, upper, lower, latest_dt, latest_price = analyze_365_day_gain(df, symbol, fetcher.std_multiplier)\n",
    "        if avg is None:\n",
    "            continue\n",
    "        \n",
    "        std = round((upper - avg) / fetcher.std_multiplier, 2)\n",
    "        upper_1std = round(avg + std, 2)\n",
    "        lower_1std = round(avg - std, 2)\n",
    "        upper_1_97std = round(avg + 1.97 * std, 2)\n",
    "        lower_1_97std = round(avg - 1.97 * std, 2)\n",
    "\n",
    "        plot_price_gain(annotated_df, symbol, avg, std, upper_1std, lower_1std, upper_1_97std, lower_1_97std)\n",
    "\n",
    "        analyzed_data[symbol] = annotated_df\n",
    "        # Before filtering\n",
    "        df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], errors=\"coerce\", utc=True)\n",
    "        ten_years_ago = pd.Timestamp.now(tz='UTC') - pd.DateOffset(years=10)\n",
    "\n",
    "        # Safe comparison\n",
    "        max_price = round(df[df['Datetime'] >= ten_years_ago][\"Close\"].max(), 2) if \"Close\" in df.columns else None\n",
    "\n",
    "        portfolio_df, ar_invest, _, _ = backtest_weekly_investment(\n",
    "            df, initial_balance=0, invest_per_week=200, tp_percent=1.0,\n",
    "            leverage=1000,\n",
    "            coeff=fetcher.coeff_map.get(symbol),\n",
    "            std=abs(lower),\n",
    "            start_date=\"1900-01-01\", end_date=\"2024-12-31\"\n",
    "        )\n",
    "\n",
    "        final_summary.append({\n",
    "            \"Symbol\": symbol, \"Date\": latest_dt, \"Price\": latest_price, \"Max Price\": max_price,\n",
    "            \"Std\": abs(lower), \"Coefficient\": fetcher.coeff_map.get(symbol), \"Annual Return (Simulated)\": ar_invest\n",
    "        })\n",
    "\n",
    "    final_df = pd.DataFrame(final_summary)\n",
    "\n",
    "    print(\"\\n✅ Final Summary:\")\n",
    "    print(final_df)\n",
    "    \n",
    "    # Upload to Google Sheets\n",
    "    try:\n",
    "        print(\"\\n📤 Uploading to Google Sheets...\")\n",
    "        uploader = GoogleSheetsUploader(CREDENTIAL_PATH, \"Financial Report - Indonesia\")\n",
    "        uploader.upload_dataframe(final_df, \"Overview\")\n",
    "        print(\"✅ Upload successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Upload failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
